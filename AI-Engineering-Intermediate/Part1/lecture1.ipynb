{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96520fca",
   "metadata": {},
   "source": [
    "# Lecture x: Response API vs Chat Completions\n",
    "\n",
    "## Topics to cover:\n",
    "1. Why use Response API over Chat Completions\n",
    "2. Streaming Responses\n",
    "3. Prompt Engineering\n",
    "4. Function Calling\n",
    "5. A Simple Agent\n",
    "\n",
    "It is a never-ending battle of being up-to-date with the latest changes in AI. There will always be changes to APIs and their documentation, new tools, deprecations of previous API endpoints and tools.\n",
    "\n",
    "Our job as AI Engineers is to make sure we are up-to-date with the relevant documentation of the tools we are using. Usually, providers will give ample notice before any major changes are introduced and old methods are depreciated.\n",
    "\n",
    "## Why the Responses API\n",
    "As mentioned in OpenAIs documentation for [Responses vs Chat Completions](https://platform.openai.com/docs/guides/responses-vs-chat-completions).\n",
    "\n",
    "- Better for agentic workflows\n",
    "- Stateful API\n",
    "- Model availability\n",
    "- Built-in tool use (Like OpenAIs own 'file search' and 'computer use')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320a59a7",
   "metadata": {},
   "source": [
    "## What the basic Chat Completions looked like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0fe3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if OPENAI_API_KEY is None:\n",
    "    raise Exception(\"API key is missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a900906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Robert Downey Jr. is an acclaimed American actor and producer, widely recognized for his versatility and for overcoming significant personal and professional challenges throughout his career. Born on April 4, 1965, in New York City, he is the son of filmmaker Robert Downey Sr.\\n\\nDowney began acting at a young age, appearing in films such as **\"Less Than Zero\"** (1987) and gaining critical acclaim for his role as Charlie Chaplin in **\"Chaplin\"** (1992, earning him an Academy Award nomination). However, his career was marred by struggles with substance abuse and legal issues in the late 1990s and early 2000s.\\n\\nHe staged a remarkable comeback and is best known in recent years for his portrayal of **Tony Stark/Iron Man** in the Marvel Cinematic Universe, beginning with **\"Iron Man\"** (2008) and reprising the role in several other Marvel films, which brought him worldwide fame and commercial success. Downey has also starred in other popular movies such as **\"Sherlock Holmes\"** (2009) and its sequel, further solidifying his status as one of Hollywood’s top actors.\\n\\nHe is admired for his charisma, wit, and the depth he brings to his roles, making him one of the most popular and highest-paid actors in the industry.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4.1\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who is Robert Downey Jr.?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f07f83c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Could you please specify which person or actor you are referring to? That way, I can provide you with the most accurate information about their most popular movie.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4.1\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is his most popular movie?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fabd86",
   "metadata": {},
   "source": [
    "## Responses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae61e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4.1\",\n",
    "  input=[\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"Who is Robert Downey Jr.?\"\n",
    "      }\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4.1\",\n",
    "  previous_response_id=response.id,\n",
    "  input=[\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"What is his most popular movie?\"\n",
    "      }\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432ba021",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3770b761",
   "metadata": {},
   "source": [
    "### Prompt Elements\n",
    "\n",
    "A prompt contains any of the following elements:\n",
    "\n",
    "**Instruction** - a specific task or instruction you want the model to perform\n",
    "\n",
    "**Context** - external information or additional context that can steer the model to better responses\n",
    "\n",
    "**Input Data** - the input or question that we are interested to find a response for\n",
    "\n",
    "**Output Indicator** - the type or format of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38ac5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def get_response(prompt: str, model: str, response_id: Optional[int] = None) -> tuple[str, int]:\n",
    "    response = client.responses.create(\n",
    "    model=model,\n",
    "    previous_response_id=response_id,\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    return response.output_text, response.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d6914",
   "metadata": {},
   "source": [
    "### 1. Zero-shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f54cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee2322e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The text fits into the **Technology** category."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "\n",
    "Classify the following text into one of the following categories:\n",
    "1. Technology\n",
    "2. Science\n",
    "3. Art\n",
    "4. History\n",
    "\n",
    "Text: The advancements in quantum computing have the potential to revolutionize the field of cryptography, enabling faster processing and more secure communication methods.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response_text, response_id = get_response(PROMPT, MODEL)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c6a59a",
   "metadata": {},
   "source": [
    "### 2. Few-shot/Multi-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f0d32ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A: Technology"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "\n",
    "Classify the following text into one of the following categories:\n",
    "\n",
    "1. Technology\n",
    "2. Science\n",
    "3. Art\n",
    "4. History\n",
    "\n",
    "Text: The advancements in quantum computing have the potential to revolutionize the field of cryptography, enabling faster processing and more secure communication methods.\n",
    "\n",
    "EXAMPLES\n",
    "\n",
    "Q: The invention of the printing press in the 15th century allowed for the mass production of books and the spread of knowledge.\n",
    "A: Technology\n",
    "\n",
    "Q: The discovery of penicillin in 1928 marked the beginning of modern antibiotics and has saved countless lives.\n",
    "A: Science\n",
    "\n",
    "Q: The Mona Lisa, painted by Leonardo da Vinci in the 16th century, is one of the most famous works of art in history.\n",
    "A: Art\n",
    "\n",
    "Q: The fall of the Berlin Wall in 1989 was a significant event in world history, symbolizing the end of the Cold War.\n",
    "A: History\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response_text, response_id = get_response(PROMPT, MODEL)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe9402",
   "metadata": {},
   "source": [
    "### 3. Chain-of-Thought (CoT) Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7f9c15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To solve this problem, we can set up equations for the distance each train travels until they meet.\n",
       "\n",
       "Let's denote:\n",
       "- t as the time (in hours) it takes for the trains to meet after the changes in speed.\n",
       "- x as the distance the 60 mph train travels at the increased speed of 80 mph.\n",
       "- y as the distance the 40 mph train travels at the decreased speed of 30 mph.\n",
       "\n",
       "For the first hour:\n",
       "- Distance traveled by the 60 mph train = 60 miles\n",
       "- Distance traveled by the 40 mph train = 40 miles\n",
       "\n",
       "After the first hour:\n",
       "- Distance traveled by the 60 mph train = 80t miles\n",
       "- Distance traveled by the 40 mph train = 30t miles\n",
       "\n",
       "Since the total distance between the cities is 300 miles, we can create the equation:\n",
       "80t + 30t = 300\n",
       "110t = 300\n",
       "t = 300 / 110\n",
       "t ≈ 2.73 hours\n",
       "\n",
       "Therefore, the two trains will meet approximately 2.73 hours after departure."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "PROMPT = \"\"\"\n",
    "\n",
    "A train leaves City A heading towards City B at 60 miles per hour.\n",
    "At the same time, another train leaves City B heading towards City A at 40 miles per hour.\n",
    "The cities are 300 miles apart. However, after 1 hour, the train from City A increases its \n",
    "speed by 20 miles per hour, and the train from City B decreases its speed by 10 miles per hour. \n",
    "How long after departure will the two trains meet?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response_text, response_id = get_response(PROMPT, MODEL)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "531b5a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Step 1: Calculate how far each train has traveled after 1 hour.\n",
       "- The train from City A travels at 60 miles per hour for 1 hour, so it has traveled 60 miles.\n",
       "- The train from City B travels at 40 miles per hour for 1 hour, so it has traveled 40 miles.\n",
       "\n",
       "Step 2: Calculate the remaining distance between the two trains after 1 hour.\n",
       "- The total distance between the two cities is 300 miles.\n",
       "- After 1 hour, the trains are 60 miles + 40 miles = 100 miles apart.\n",
       "\n",
       "Step 3: Calculate the relative speed between the two trains after 1 hour.\n",
       "- The relative speed between the two trains is 60 miles per hour + 40 miles per hour = 100 miles per hour.\n",
       "\n",
       "Step 4: Determine how long it takes for the trains to cover the remaining distance while moving towards each other at the increased and decreased speeds.\n",
       "- The train from City A increases its speed by 20 miles per hour, making its new speed 80 miles per hour.\n",
       "- The train from City B decreases its speed by 10 miles per hour, making its new speed 30 miles per hour.\n",
       "- The combined speed of the trains moving towards each other is 80 miles per hour + 30 miles per hour = 110 miles per hour.\n",
       "- The remaining distance between the trains is 200 miles (300 miles - 100 miles).\n",
       "- To cover 200 miles at 110 miles per hour, it will take 200 miles / 110 miles per hour = 1.82 hours.\n",
       "\n",
       "Step 5: Calculate the total time taken for the trains to meet.\n",
       "- The initial 1 hour + the additional 1.82 hours = 2.82 hours.\n",
       "- Therefore, the two trains will meet 2.82 hours after departure.\n",
       "\n",
       "Therefore, the two trains will meet approximately 2.82 hours after departure."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "\n",
    "A train leaves City A heading towards City B at 60 miles per hour. \n",
    "At the same time, another train leaves City B heading towards City A at 40 miles per hour. \n",
    "The cities are 300 miles apart. However, after 1 hour, the train from City A increases its \n",
    "speed by 20 miles per hour, and the train from City B decreases its speed by 10 miles per hour. \n",
    "How long after departure will the two trains meet?\n",
    "\n",
    "Think about this problem step by step.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response_text, response_id = get_response(PROMPT, MODEL)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863ba617",
   "metadata": {},
   "source": [
    "### Technique 1: Write clear and concise instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b39859",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"I need to buy a birthday present for my sister\"\n",
    "\n",
    "response_text, response_id = get_response(PROMPT)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd41cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"I need to buy a birthday present for my sister. She is 12 years old and is interested in ponies. Reply only with 2 options.\"\n",
    "\n",
    "response_text, response_id = get_response(PROMPT)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e7ba80",
   "metadata": {},
   "source": [
    "### Technique 2: Split your task into simpler subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362bf0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "\n",
    "Write an article about the importance of muscle for skeletal health and mobility in old age.\n",
    "\n",
    "Follow these guidelines:\n",
    "- Jot down high-level bullets on the subject\n",
    "- Write a short introduction\n",
    "- Write a detailed section on the importance of muscle for skeletal health\n",
    "- Write a detailed section on the importance of muscle for mobility\n",
    "- Write a conclusion summarizing the key points\n",
    "- Use markdown formatting\n",
    "- Use a friendly and engaging tone\n",
    "- Use simple language that is easy to understand\n",
    "- Use a maximum of 500 words\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c0eb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text, response_id = get_response(PROMPT)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4344431",
   "metadata": {},
   "source": [
    "### Technique 3: Allow GPT to think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a35e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "\n",
    "You will be tasked to build a simple application using Python and Flask.\n",
    "\n",
    "You MUST plan effectively, thinking through each step before you write code.\n",
    "\n",
    "I want you to build an app that, upon clicking a button, will generate random Yoda quotes.\n",
    "\n",
    "# Workflow\n",
    "\n",
    "## High-level problem solving strategy\n",
    "1. Deeply understand the user's requirements.\n",
    "2. Break down the requirements into smaller tasks.\n",
    "3. For each task, think through the implementation details.\n",
    "4. Write code for each task, ensuring it works correctly.\n",
    "5. Test the code to ensure it meets the requirements.\n",
    "\n",
    "## Code implementation strategy\n",
    "1. Start with the main application structure.\n",
    "2. Implement the core functionality.\n",
    "3. Add any additional features as needed.\n",
    "\n",
    "## Other notes:\n",
    "1. The app should look sleep and modern\n",
    "2. It should feel snappy\n",
    "3. Do not ask any questions\n",
    "4. Give me the entire code in one file\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text, response_id = get_response(PROMPT)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b612c1bb",
   "metadata": {},
   "source": [
    "Let's compare with bad prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9cf485",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"I want you to build an app that, upon clicking a button, will generate random Yoda quotes. The app should be sleek and modern and snappy. Give me all the code in one python file.\"\n",
    "\n",
    "response_text, response_id = get_response(PROMPT)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad15c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
