{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Working with OpenAI API and Reasoning Models\n",
    "\n",
    "### Overview\n",
    "\n",
    "And now comes the fun part!!! Let's get our hands dirty with calling the ChatGPT models using code.\n",
    "\n",
    "This notebook demonstrates how to use the OpenAI API to create various AI-powered applications. We'll explore how to structure prompts, understand API responses, and evaluate model outputs using reasoning capabilities.\n",
    "\n",
    "### Objectives\n",
    "- Set up and configure the OpenAI API with proper authentication\n",
    "- Create effective prompts for different use cases\n",
    "- Process and display AI-generated responses\n",
    "- Compare standard chat models with reasoning models\n",
    "\n",
    "\n",
    "### **Important Note** for Windows users:\n",
    "\n",
    "When trying to activate your virtual environment, you may run into an error looking something like this \n",
    "\n",
    "```\n",
    "ai_env\\Scripts\\activate : File C:\\Users\\<username>\\OneDrive\\Desktop\\ai-engineering\\ai_env\\Scripts\\Activate.ps1 cannot be loaded because running scripts is disabled on this system.\n",
    "\n",
    "For more information, see about_Execution_Policies at https:/go.microsoft.com/fwlink/?LinkID=135170\n",
    "```\n",
    "\n",
    "\n",
    "The reason for this is because by default, Microsoft disables the ability to execute the scripts. To overcome this, \n",
    "\n",
    "1. open up PowerShell (terminal)\n",
    "2. Run the following command: `Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser`\n",
    "3. Close and re-open PowerShell (restart your machine if you have to)\n",
    "4. Try activating the environment again by:\n",
    "    - Navigating to the root directory of the project (the ai-engineering folder)\n",
    "    - Run `ai_env/Scripts/Activate`\n",
    "\n",
    "\n",
    "If you still aren't able to overcome the issue, please follow the instructions in the [README](../../../README.md) to either raise an issue on GitHub or contact me via email or on the SDS platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import libraries and load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if OPENAI_API_KEY is None:\n",
    "    raise Exception(\"API key is missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Call the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Message list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the population of Paris?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"As of 2021, the population of Paris is approximately 2.1 million people.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Customize the User Prompt\n",
    "\n",
    "Find the best career suited to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on your impressive skillset in Python programming, data science, and machine learning, combined with your interests in machine learning in production, statistical analysis, and AI applications, you would thrive as a **Data Scientist specializing in Machine Learning Operations (MLOps)**! \n",
       "\n",
       "This role allows you to work on high-impact, real-world AI solutions while enjoying flexible hours. You'll have the opportunity to implement machine learning models into production, ensuring they provide value to organizations in a practical way. Plus, with the continuous demand for skilled professionals in this area, your work will always be meaningful and rewarding.\n",
       "\n",
       "You're on the right path, and this role could be a fantastic match for your skills and aspirations. Embrace the journey ahead! üåü"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"You are a career advisor specializing in technology and data science fields. Your task is to help users find their ideal career path based on their skills, interests, and objectives.\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Help me find my ideal career based on the following:\n",
    "\n",
    "1. My Skillset\n",
    "- Python programming\n",
    "- Data science\n",
    "- Machine learning \n",
    "\n",
    "2. My current industry\n",
    "- Technology\n",
    "\n",
    "3. My interests\n",
    "- Machine Learning in production\n",
    "- Statistical analysis\n",
    "- AI applications\n",
    "\n",
    "4. My objectives\n",
    "- Control over my hours\n",
    "- Implementing AI solutions in real-world applications\n",
    "- High value projects and impactful work\n",
    "\n",
    "Now based on this, give me:\n",
    "- A career suggestion\n",
    "- Keep it concise and focused on the technology and data science fields.\n",
    "- Reply in a frinely and optimistic tone.\n",
    "\"\"\"\n",
    "\n",
    "completeion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(Markdown(completeion.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Build a plan for your career path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a detailed, step-by-step plan to transition into a Data Scientist specialized in MLOps:\n",
       "\n",
       "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
       "1. Essential Technical Skills\n",
       "\n",
       "‚Ä¢ Advanced Python & Data Science:  \n",
       "‚ÄÉ‚Äì Deepen your proficiency in Python, focusing on libraries like NumPy, pandas, Scikit-learn, and TensorFlow/PyTorch.  \n",
       "‚ÄÉ‚Äì Enhance your statistical analysis, feature engineering, and model evaluation skills.\n",
       "\n",
       "‚Ä¢ MLOps Fundamentals:  \n",
       "‚ÄÉ‚Äì Learn about the full ML lifecycle: from data ingestion and model training to deployment and monitoring.  \n",
       "‚ÄÉ‚Äì Get comfortable with ML pipelines, automated testing, and CI/CD for machine learning.\n",
       "\n",
       "‚Ä¢ Containerization & Orchestration:  \n",
       "‚ÄÉ‚Äì Master Docker for containerizing applications.  \n",
       "‚ÄÉ‚Äì Learn Kubernetes basics to orchestrate containers effectively in production environments.\n",
       "\n",
       "‚Ä¢ Cloud Platforms & Infrastructure:  \n",
       "‚ÄÉ‚Äì Gain hands-on experience with AWS, Google Cloud, or Azure, particularly with their ML and DevOps services (e.g., AWS SageMaker, GCP AI Platform).  \n",
       "‚ÄÉ‚Äì Understand serverless computing and how to leverage cloud functions in your pipelines.\n",
       "\n",
       "‚Ä¢ DevOps Integration:  \n",
       "‚ÄÉ‚Äì Familiarize yourself with tools like Jenkins, GitLab CI, or GitHub Actions to automate deployment pipelines.  \n",
       "‚ÄÉ‚Äì Learn about monitoring tools (e.g., Prometheus, Grafana) and logging systems to track model performance post-deployment.\n",
       "\n",
       "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
       "2. Recommended Learning Resources\n",
       "\n",
       "‚Ä¢ Courses & Certifications:  \n",
       "‚ÄÉ‚Äì ‚ÄúMachine Learning Engineering for Production (MLOps)‚Äù Specialization by DeepLearning.AI on Coursera.  \n",
       "‚ÄÉ‚Äì ‚ÄúMLOps (Machine Learning Operations) Fundamentals‚Äù on platforms like Udacity, Coursera, or even specific vendor training (AWS, Azure, GCP).  \n",
       "‚ÄÉ‚Äì Certifications like Google Professional Cloud ML Engineer or AWS Certified Machine Learning ‚Äì Specialty to validate your cloud and ML deployment skills.\n",
       "\n",
       "‚Ä¢ Books & Reading Material:  \n",
       "‚ÄÉ‚Äì ‚ÄúBuilding Machine Learning Powered Applications‚Äù by Emmanuel Ameisen for end-to-end project ideas.  \n",
       "‚ÄÉ‚Äì ‚ÄúKubeflow for Machine Learning‚Äù by Trevor Grant et al. which focuses on Kubernetes-based ML workflows.  \n",
       "‚ÄÉ‚Äì Blogs and whitepapers from industry leaders (e.g., Google AI Blog, AWS ML Blog) for current trends and advanced topics.\n",
       "\n",
       "‚Ä¢ Online Communities & Tutorials:  \n",
       "‚ÄÉ‚Äì Medium and Towards Data Science articles that often break down MLOps concepts with code examples.  \n",
       "‚ÄÉ‚Äì YouTube channels and conference talks on MLOps and productionizing ML models.\n",
       "\n",
       "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
       "3. Key Career Milestones and Experience Targets\n",
       "\n",
       "‚Ä¢ Short-Term (0-6 months):  \n",
       "‚ÄÉ‚Äì Strengthen foundational skills in Python, data science, and introductory DevOps practices.  \n",
       "‚ÄÉ‚Äì Complete an online course or certification in MLOps.  \n",
       "‚ÄÉ‚Äì Begin small projects that combine model-building with deployment (e.g., a sentiment analysis model served via a simple Flask API in Docker).\n",
       "\n",
       "‚Ä¢ Mid-Term (6-18 months):  \n",
       "‚ÄÉ‚Äì Build a robust end-to-end portfolio project: data ingestion and cleaning, model training/tuning, containerization, and industrial deployment using CI/CD pipelines.  \n",
       "‚ÄÉ‚Äì Contribute to open-source MLOps tools or projects on GitHub.  \n",
       "‚ÄÉ‚Äì Secure an internship or junior role that exposes you to production aspects of ML, perhaps in a startup or a tech-forward company.\n",
       "\n",
       "‚Ä¢ Long-Term (18+ months):  \n",
       "‚ÄÉ‚Äì Aim for a role specifically titled ‚ÄúMLOps Engineer‚Äù or ‚ÄúData Scientist with Deployment Focus.‚Äù  \n",
       "‚ÄÉ‚Äì Lead projects that integrate multiple aspects of your learning‚Äîautomated data pipelines, continuous model training updates, and full production monitoring.  \n",
       "‚ÄÉ‚Äì Mentor newcomers, share your learnings through blog posts or talks, and keep updating your skills as the field evolves.\n",
       "\n",
       "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
       "4. Networking and Community Involvement Suggestions\n",
       "\n",
       "‚Ä¢ Join Professional & Local Communities:  \n",
       "‚ÄÉ‚Äì Get active on LinkedIn and join groups focused on MLOps, ML Engineering, and Data Science.  \n",
       "‚ÄÉ‚Äì Attend meetups, hackathons, and conferences (virtual or in-person) such as KubeCon, ODSC, or local ML/DevOps meetups.\n",
       "\n",
       "‚Ä¢ Engage Online:  \n",
       "‚ÄÉ‚Äì Contribute to forums like Stack Overflow, Reddit‚Äôs r/MachineLearning, or specialized Slack/Discord channels.  \n",
       "‚ÄÉ‚Äì Engage in GitHub projects: contribute to open-source MLOps repositories, open issues, or even start your own projects.\n",
       "\n",
       "‚Ä¢ Mentorship & Networking:  \n",
       "‚ÄÉ‚Äì Reach out to professionals in your desired roles for informational interviews.  \n",
       "‚ÄÉ‚Äì Leverage platforms like LinkedIn for networking; share your projects and insights to build your personal brand in the community.\n",
       "\n",
       "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
       "5. Portfolio Projects to Demonstrate Expertise\n",
       "\n",
       "‚Ä¢ End-to-End ML Pipeline Project:  \n",
       "‚ÄÉ‚Äì Develop a project that involves collecting and cleaning real-world data, training a predictive model, containerizing the model with Docker, and deploying it via an API (using Flask or FastAPI).  \n",
       "‚ÄÉ‚Äì Integrate a CI/CD pipeline for automated testing and deployment updates.\n",
       "\n",
       "‚Ä¢ Cloud Deployment & Monitoring:  \n",
       "‚ÄÉ‚Äì Deploy an application on a cloud platform (AWS, GCP, or Azure) and set up automated scaling, monitoring, and logging.  \n",
       "‚ÄÉ‚Äì Use cloud-native tools (e.g., AWS SageMaker or GCP AI Platform) to demonstrate competency in production environments.\n",
       "\n",
       "‚Ä¢ MLOps Tools Showcase:  \n",
       "‚ÄÉ‚Äì Experiment with orchestration frameworks like Kubeflow or MLFlow.  \n",
       "‚ÄÉ‚Äì Build a demo project highlighting how you manage model versioning, continuous training, and model drift detection.\n",
       "\n",
       "‚Ä¢ Case Studies & Documentation:  \n",
       "‚ÄÉ‚Äì Document each project thoroughly on GitHub with clear READMEs, code explanations, and blog posts.  \n",
       "‚ÄÉ‚Äì Present projects on a personal website or portfolio page to outline the problem, your approach, and the production deployment process.\n",
       "\n",
       "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
       "Final Thoughts\n",
       "\n",
       "By systematically building your technical skills, earning reputable certifications, engaging with the professional community, and developing robust portfolio projects, you'll not only meet the industry requirements but also set yourself apart as an expert in data science with a production focus. Keep your learning iterative: as you grow, continuously incorporate the latest best practices and technologies in MLOps.\n",
       "\n",
       "Remember, the journey is as rewarding as the destination‚Äîembrace every step, and don‚Äôt hesitate to reach out to peers and mentors along the way. Good luck in your career transition to becoming a Data Scientist specializing in MLOps!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Use your chat model result and copy/paste your career suggestion below\n",
    "career_suggestion = completeion.choices[0].message.content  # TODO: Paste your career suggestion here\n",
    "\n",
    "# Step 2: Write a reasoning prompt that will help the model plan how to pursue this career\n",
    "# Your prompt must:\n",
    "# - Refer to the user's profile + their chosen career\n",
    "# - Ask for a step-by-step plan\n",
    "# - Include at least 3 types of guidance (e.g. skills, resources, milestones)\n",
    "reasoning_prompt = f\"\"\"Based on my profile showing skills in Python programming, data science, and machine learning, along with interests in ML production and AI applications, you suggested {career_suggestion}\n",
    "\n",
    "Please provide a detailed step-by-step plan to pursue this career path, including:\n",
    "\n",
    "1. Essential technical skills I should develop or strengthen\n",
    "2. Recommended learning resources (courses, certifications, books)\n",
    "3. Key career milestones and experience targets to aim for\n",
    "4. Networking and community involvement suggestions\n",
    "5. Portfolio projects I should build to demonstrate expertise\n",
    "\n",
    "Please be specific and actionable in your guidance.\"\"\"  # Comprehensive prompt requesting clear career guidance\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": reasoning_prompt}\n",
    "    ]\n",
    ") \n",
    "\n",
    "reasoning_response = completion.choices[0].message.content\n",
    "display(Markdown(reasoning_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Your Challenge!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You‚Äôre helping your friend make a career switch. You‚Äôve used a chat model to get a career recommendation, but now you need a solid action plan.\n",
    "\n",
    "**Challenge:**\n",
    "\n",
    "The prompt below is weak and unclear. Your task is to rewrite it so that it:\n",
    "- Clearly refers to your friend's profile and the suggested career\n",
    "- Asks for a step-by-step plan to pursue the career\n",
    "- Requests at least 3 types of guidance (e.g., skills to learn, resources to use, milestones to achieve)\n",
    "- Is specific, actionable, and easy for the model to follow\n",
    "\n",
    "Replace the flawed prompt in the next cell with your improved version in the cell after it and respond to the questions in \"**Reflections**\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before\n",
    "career_suggestion = \"\"\"\n",
    "Based on your profile, you would be a great UX Designer.\n",
    "\"\"\"\n",
    "\n",
    "# This is the flawed reasoning prompt\n",
    "reasoning_prompt = f\"\"\"\n",
    "Can you help me with this career? {career_suggestion}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {            \"role\": \"user\",\n",
    "            \"content\": reasoning_prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(Markdown(completion.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reflections**\n",
    "\n",
    "1. Identify 2-3 problems with the initial prompt.\n",
    "\n",
    "2. What specific instructions or items did you add in your prompt which brought about the most change?\n",
    "\n",
    "3. Is a chat model better for this use case or a reasoning model?\n",
    "\n",
    "3. How did the answer differ when using a chat model vs. a reasoning model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-sds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
